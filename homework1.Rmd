---
title: "Panel Data Homework 1"
author: "Ian Kennedy in collaboration with Mark Igra"
date: "`r format(Sys.Date(),'%m/%d/%Y')`"
output: 
  bookdown::pdf_document2:
    latex_engine: xelatex
    toc: no
    number_sections: no
    fig_caption: yes
    fig_width: 4
    fig_height: 3
header-includes: 
- \usepackage{graphicx}
- \usepackage{float}
- \usepackage{dsfont}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, message=FALSE, warning=FALSE, autodep=TRUE,
                      cache=FALSE, cache.path="./cache/",
                      fig.align='center', fig.pos='H')
```

```{r, include=TRUE, message=FALSE}
library(knitr)
library(xtable)
library(tidyverse)
library(bookdown)
library(data.table)
```

# Problem 1: Identifying unknown stationary time series processes  

**[54 points.]** In the file `mysterytsUW.csv`, you will find 18 columns of time series data. Each column is an independent time series generated by your instructor to have a particular structure. That structure might include a deterministic time trend, seasonal effects, AR(p) processes, and/or MA(q) process. All of these time series can be assumed to be covariance stationary.  
For each series, your task is to make your best guess of the data generating process (DGP) which produced the data. Thus, for each time series a. to r., you should in- dicate whether you suspect the time series DGP includes any of the following four components:  

i. *deterministic trend* If you suspect a deterministic trend, indicate your evidence for that trend, describe it (e.g., with an estimate of the monthly increase or de- crease) and then remove it from the time series to yield a detrended time series for further analysis.  

ii. *seasonality* Assume the data are monthly, so that any seasonality should show up on a 12 observation cycle. In this case, assume that any seasonality present is additive.^I[Multiplicative seasonality is more common but is not used in this example.] If you suspect seasonality, describe the seasonal cycle, then remove the seasonal means from your data to yield a seasonally-adjusted time series.  

iii. *autoregression* If you suspect autoregression is present, describe the order of autoregression and the likely signs and magnitudes of terms. Be sure to use detrended and/or seasonally-adjusted data if you found either a time trend or seasonality.  

iv. *moving averages* If you suspect moving average components are present in the error term, describe the order of the moving average process and the likely signs and magnitudes of terms. Be sure to use detrended and/or seasonally-adjusted data if you found either a time trend or seasonality.  


The first 12 time series – a. to l. – contain at most one of the four components above. The remaining six time series – m. to r. – may contain more than one component.  
Use any tools you know, including graphs of the time series, correlograms of auto- correlations (ACFs), and correlograms of partial autocorrelations (PACFs). It may be useful to apply these tools to the original, detrended, and/or seasonally ajusted time series. It is not necessary to show every graph you make; often a sentence summarizing a plot will be sufficient, but if you are in doubt, show and describe the plot.  
You will be marked on the basis of your choice and use of appropriate diagnostic tools. You will not be penalized for failure to guess time series processes correctly, unless this reveals deficiencies in your understanding of diagnostic tools.  

```{r include = FALSE}
ts <- fread('data/mysterytsUW.txt') %>% mutate(month = rep(month.name, 9)[1:100], year = floor(0:99/12), date = str_c(month, '-', year), row = 1:100) %>% pivot_longer(names_to = 'series', cols = 1:18, values_to = 'value')

ts %>% ggplot(aes(row, value))+
  geom_line()+
  facet_wrap(~series, scales = 'free')


walk(unique(ts$series), function(x) acf(ts %>% filter(series == x) %>% pull(value)))
```

Deterministic trends in c, k, n, p, possibly o and r. 

```{r figure 1}
focal_series = ts %>% filter(series == 'a')
acf(focal_series$value, main = "Figure 1: CF of Series 'A'")
```

a. No temporal autocorrelation, moving average, deterministic trend, or seasonality. While the acf (figure 1) and pacf show a negative and significant spike in the second order. At first I thought that could mean that either the spike was spurious or we had an ACF(2) with a very low $\phi_1$  and a $phi_2$ of about .45. But when I tried simulating that data with that structure, the ACF plot looked very different: there was always a significant first order spike. I even tried making $\phi_1$  really low and $\phi_2$ really high, but no dice. So i'm convinced that A is just error around the mean in which the data from two periods ago happens to be negatively associated with the current data. Eyballing the plot and ACF also seemed to rule out deterministic trends and seasonality. Running a regression with the observation# and month as variables showed they were not good predictors of the value.


b. Eyeballing B suggests some seasonality. The PACF and ACF both also have spikes on 12, which supports that intuition. Regression of the monthly values on the observation number and month further confirms this pattern: looks like something big happens in December.  

c. C pretty clearly has a deterministic trend. Regressing on the observation number confirms that intuition. We can detrend the data, as shown in figure 2.  

```{r figure 2}
focal_series = ts %>% filter(series == 'c')
trend_model = lm(value ~ row, data = focal_series)
focal_series %>% mutate(detrend = value-trend_model$fitted.values) %>% 
  pivot_longer(c(detrend, value), values_to = 'value') %>%
  ggplot(aes(row, value, color = name))+
  geom_line() + 
  scale_color_brewer(palette = 10)+
  ggtitle("Figure 2: Original and Detrened Series 'C'") +
  theme_classic()
```

d. Ok, here eyeballing and other checks count out deterministic trends. The `decomposed()` function suggests seasonality, which is confirmed by the PACF and ACF, with spikes at 12 for each. Regression analysis does not suggest particular patterns for particular months, however.  

e. Eyeballing doesn't suggest any deterministic trend. This time, though `decomposed()` agian suggests seasonality, the ACF and PACF tell a different story: this is an AR(1) process with $phi = .7$ or so.  

f. It looks like there's some seasonality in F, confirmed by decomposition, and by the ACF and PACF. Unlike in D, however, removing the monthly patterns does seem to have an effect in this case. Figure 3 and 4 show the ACF of the raw seasonality-adjusted D respectively, suggesting that the monthy pattern was the only temporal pattern present.  

```{r}
focal_series = ts %>% filter(series == 'f')
trend_model = lm(value ~ row + month, data = focal_series)
acf(focal_series$value,
     main = "Figure 3: ACF of 'D'")
acf(focal_series %>% mutate(detrend = value-trend_model$fitted.values) %>% pull(detrend),
     main = "Figure 4: ACF of Seasonality-Adjusted 'D'")
```


```{r include = FALSE}

focal_series = ts %>% filter(series == 'f')
focal.ts <- ts(focal_series$value, start=c(2010,1), frequency=12)
plot(decompose(focal.ts))
summary(lm(value ~ row + month, data = focal_series #%>%  mutate(month = as.numeric(as_factor(month)))
           ))
trend_model = lm(value ~ row + month, data = focal_series)
focal_series %>%
  ggplot(aes(row, value))+
  geom_line() + 
  scale_color_brewer(palette = 10)+
  ggtitle("Figure 2: Original and Detrened Series 'C'") +
  theme_classic()
focal_series %>% mutate(detrend = value-trend_model$fitted.values) %>% 
  pivot_longer(c(detrend, value), values_to = 'value') %>%
  ggplot(aes(row, value, color = name))+
  geom_line() + 
  scale_color_brewer(palette = 10)+
  ggtitle("Figure 2: Original and Detrened Series 'C'") +
  theme_classic()
acf(focal_series$value,
     main = "Figure 3: ACF of 'D'")
acf(focal_series %>% mutate(detrend = value-trend_model$fitted.values) %>% pull(detrend),
     main = "Figure 4: ACF of Seasonality-Adjusted 'D'")
pacf(focal_series$value)
summary(lm(value ~ row + month, data = focal_series))
```



# Problem 2: Identifying unknown, possibly nonstationary time series processes  


**[15 points.]** In this problem, we focus on the problem of identifying nonstationarity. In the file `mysterytsUW2.csv`, you will find five additional time series, s. to w. Once again, each column is an independent time series generated to have a particular structure. All of these series follow some AR(p) process. No moving average processes, deterministic trends, or seasonal variation are present in these time series. However, these five time series are not guaranteed to be covariance stationary. For each time series:  

i. Subset the first 20 observations. Plot them against time and plot the ACFs and PACFs. (There is no need to show these graphs on your write-up.) Based on these plots, guess the order of the AR(p), and the approximate values of the au- toregressive parameters.  

ii. Subset the first 100 observations and repeat the analysis. Did any of your con- clusions change or become more or less certain?  

iii. Conduct your analysis on all 1000 observations. Did any of your conclusions change? If so, what implications does this have for assessing stationarity in time series in your field?  


# Problem 3: Student project checkpoint

*If you are working with other students in the class, please identify them; you should jointly write this section of the homework. Please submit this problem separately from the problems above: one copy per group! Email your group’s response to this problem to cadolph@uw.edu.*

**[31 points.]** Provide a brief (2–3 paragraph) summary of your proposed research de- sign. The key questions to answer:  

• What is the outcome studied in your analysis? What range of values can it take on?  
• Whatistheunitofanalysis?Inparticular,whatisthenumberofcross-sectional units N and the number of periods T? Is there anything unusual about the selec- tion or observation of units or time periods?  
• Is there any pattern of missing data and/or selection of data?  
• In what ways do you think different observations over time may be related (dependent) in your data?  
• Do you suspect any Gauss-Markov assumptions would violated if these data were analyzed with a simple linear regression?  
• Based on what you have learned so far, what methods might be appropriate for analyzing your data? If you have the data in hand, you should provide histograms and/or density plots of the dependent variable, as well as any other relevant diagnostics to support your answers.  

